# ASR_Experiments
Cette branche contient plusieurs expÃ©riences liÃ©es Ã  la **reconnaissance automatique de la parole (ASR)**.

---

### `pre-process.py`

Ce script prÃ©pare les donnÃ©es audio pour l'entraÃ®nement auto-supervisÃ© :

- ğŸ” Parcourt un rÃ©pertoire de fichiers `.wav` rÃ©cursivement.
- ğŸš« Ignore automatiquement les fichiers contenant certains noms (par dÃ©faut : `Emilie_K`, `Fabiano`).
- ğŸ”„ RÃ©Ã©chantillonne les fichiers Ã  16 kHz sâ€™ils ne le sont pas dÃ©jÃ .
- âœ‚ï¸ DÃ©coupe les fichiers audio longs en segments de 10 Ã  20 secondes, avec un **recouvrement de 2 secondes** entre les morceaux pour Ã©viter la perte d'information.
- ğŸ’¾ Sauvegarde les fichiers traitÃ©s dans un rÃ©pertoire de sortie spÃ©cifiÃ©.

âœ… Ce traitement est essentiel pour garantir que les donnÃ©es audio respectent les contraintes de format et de durÃ©e attendues par le modÃ¨le Wav2Vec2.

---
### `train_wav2vec.py`

Ce script lance **l'entraÃ®nement auto-supervisÃ©** dâ€™un modÃ¨le `Wav2Vec2ForPreTraining` Ã  lâ€™aide de la bibliothÃ¨que ğŸ¤— **Transformers** :

- âš™ï¸ DÃ©finit une **configuration personnalisÃ©e** du modÃ¨le (taille des couches, nombre de tÃªtes dâ€™attention, masquage temporel, etc.).
- ğŸ“¦ Charge un **jeu de donnÃ©es audio prÃ©traitÃ©** au format HuggingFace (`load_from_disk`).
- ğŸ› ï¸ Configure les **paramÃ¨tres d'entraÃ®nement** (batch size, accumulation de gradient, logs TensorBoard, prÃ©cision mixte, etc.).
- ğŸš€ Utilise la classe `Trainer` pour gÃ©rer lâ€™entraÃ®nement.
- ğŸ§  EntraÃ®ne le modÃ¨le **sans transcriptions**, uniquement Ã  partir du signal audio (apprentissage auto-supervisÃ©).

ğŸ¯ Ce script permet de dÃ©velopper un modÃ¨le Wav2Vec2 adaptÃ© Ã  un domaine ou Ã  une langue spÃ©cifique, mÃªme en lâ€™absence de donnÃ©es annotÃ©es.

---
## `vad_pyannote.py` â€“ Voice Activity Detection (VAD) avec PyAnnote

Ce script applique la **dÃ©tection dâ€™activitÃ© vocale (VAD)** en utilisant le modÃ¨le prÃ©-entraÃ®nÃ© [pyannote-audio](https://github.com/pyannote/pyannote-audio) pour filtrer les zones non parlÃ©es dans les fichiers audio. Il gÃ©nÃ¨re des fichiers `.wav` contenant uniquement les segments de parole ainsi que des fichiers `.rttm` avec les timestamps des segments dÃ©tectÃ©s. 

### ğŸ“Œ But

Ce script doit Ãªtre lancÃ© **avant `pre-process.py`**. Il permet de rÃ©duire le bruit et lâ€™audio non pertinent en :
- Supprimant les parties silencieuses ou non parlÃ©es
- Conservant uniquement les rÃ©gions oÃ¹ la parole est prÃ©sente
- Exportant les timestamps des segments de parole dÃ©tectÃ©s au format **RTTM**
- 

# Pipeline de Fine-Tuning de Whisper pour le Kriol

Ce dÃ©pÃ´t contient un pipeline complet pour fine-tuner le modÃ¨le ASR Whisper d'OpenAI sur le Kriol, une langue crÃ©ole Ã  base portugaise parlÃ©e en GuinÃ©e-Bissau et en Casamance. Le pipeline est conÃ§u pour des scÃ©narios Ã  faibles ressources, avec peu de donnÃ©es transcrites, et optimisÃ© pour la reproductibilitÃ©, l'analyse linguistique et le dÃ©ploiement sur le terrain.

## ğŸ“ Structure du dÃ©pÃ´t

- `whisper_trainer.py` â€” fine-tuning de Whisper avec Hugging Face Trainer
- `whisper_infer.py` â€” infÃ©rence Ã  partir du modÃ¨le entraÃ®nÃ©
- `whisper_train.slurm` â€” script SLURM pour entraÃ®nement sur cluster avec LETO
- `whisper_kriol_cm.csv` â€” corpus segmentÃ© avec transcriptions et Ã©tiquettes de variÃ©tÃ©s
- `simple_normalization.py`â€” outils de nettoyage et vÃ©rification orthographique

## ğŸ§  PrÃ©requis

- Python 3.8+
- PyTorch avec support GPU
- `transformers`, `datasets`, `torchaudio`, `evaluate`, `accelerate`
- Environnement Conda (ex: `training`)

Installation :
```bash
pip install transformers datasets torchaudio evaluate accelerate



