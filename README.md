# ASR_Experiments
Cette branche contient plusieurs expÃ©riences liÃ©es Ã  la **reconnaissance automatique de la parole (ASR)**.

---
# Pipeline de PrÃ©traitement et d'EntraÃ®nement Auto-SupervisÃ© avec Wav2Vec2

## `vad_pyannote.py` â€” DÃ©tection d'ActivitÃ© Vocale (VAD) avec PyAnnote

Ce script applique la **dÃ©tection dâ€™activitÃ© vocale (VAD)** en utilisant le modÃ¨le prÃ©-entraÃ®nÃ© [pyannote-audio](https://github.com/pyannote/pyannote-audio).

### ğŸ¯ Objectif

Ce traitement est lancÃ© **avant `pre-process.py`** pour filtrer les zones non parlÃ©es dans les fichiers `.wav`. Il permet de :

- ğŸ”‡ Supprimer les parties silencieuses
- ğŸ—£ï¸ Conserver uniquement les segments contenant de la parole
- ğŸ•’ GÃ©nÃ©rer des fichiers `.rttm` avec les timestamps dÃ©tectÃ©s
- ğŸ’¾ Sauvegarder des `.wav` nettoyÃ©s pour l'Ã©tape suivante

---

## `pre-process.py` â€” PrÃ©paration des DonnÃ©es Audio

Ce script prÃ©pare les fichiers audio pour l'entraÃ®nement auto-supervisÃ© Wav2Vec2.

### âš™ï¸ Ã‰tapes du pipeline

- ğŸ” Parcourt rÃ©cursivement un rÃ©pertoire contenant des fichiers `.wav`
- ğŸš« Ignore les fichiers contenant certains noms (`Emilie_K`, `Fabiano`, etc.)
- ğŸ”„ RÃ©Ã©chantillonne tous les fichiers Ã  **16 kHz mono**
- âœ‚ï¸ DÃ©coupe les longs fichiers en segments de **10 Ã  20 secondes**, avec **2 secondes de recouvrement**
- ğŸ’¾ Sauvegarde les segments dans un rÃ©pertoire de sortie structurÃ©

âœ… Ce traitement garantit la conformitÃ© du corpus audio avec les exigences de format du modÃ¨le Wav2Vec2.

---

## `train_wav2vec.py` â€” EntraÃ®nement Auto-SupervisÃ© avec Transformers

Ce script lance l'entraÃ®nement auto-supervisÃ© du modÃ¨le `Wav2Vec2ForPreTraining` via ğŸ¤— HuggingFace.

### âš™ï¸ Fonctions principales

- ğŸ“ DÃ©finit une **configuration sur mesure** du modÃ¨le (couches, tÃªtes, masquage, etc.)
- ğŸ“‚ Charge un corpus audio prÃ©traitÃ© (`load_from_disk`)
- ğŸ› ï¸ Configure les **paramÃ¨tres d'entraÃ®nement** (batch size, logs, fp16, etc.)
- ğŸš€ Lance lâ€™entraÃ®nement avec la classe `Trainer`
- ğŸ§  Apprend directement Ã  partir du **signal audio brut**, sans besoin de transcriptions

ğŸ¯ Ce pipeline permet dâ€™adapter un modÃ¨le Wav2Vec2 Ã  une langue ou un domaine spÃ©cifique en lâ€™absence de donnÃ©es annotÃ©es.

- 

# Pipeline de Fine-Tuning de Whisper pour le Kriol

Ce dÃ©pÃ´t contient un pipeline complet pour fine-tuner le modÃ¨le ASR Whisper d'OpenAI sur le Kriol, une langue crÃ©ole Ã  base portugaise parlÃ©e en GuinÃ©e-Bissau et en Casamance. Le pipeline est conÃ§u pour des scÃ©narios Ã  faibles ressources, avec peu de donnÃ©es transcrites, et optimisÃ© pour la reproductibilitÃ©, l'analyse linguistique et le dÃ©ploiement sur le terrain.

## ğŸ“ Structure du dÃ©pÃ´t

- `whisper_trainer.py` â€” fine-tuning de Whisper avec Hugging Face Trainer
- `whisper_infer.py` â€” infÃ©rence Ã  partir du modÃ¨le entraÃ®nÃ©
- `whisper_train.slurm` â€” script SLURM pour entraÃ®nement sur cluster avec LETO
- `whisper_kriol_cm.csv` â€” corpus segmentÃ© avec transcriptions et Ã©tiquettes de variÃ©tÃ©s
- `simple_normalization.py`â€” outils de nettoyage et vÃ©rification orthographique

## ğŸ§  PrÃ©requis

- Python 3.8+
- PyTorch avec support GPU
- `transformers`, `datasets`, `torchaudio`, `evaluate`, `accelerate`
- Environnement Conda (ex: `training`)

Installation :
```bash
pip install transformers datasets torchaudio evaluate accelerate

```

## ğŸ”„ AperÃ§u du pipeline

### 1. PrÃ©parer le CSV

CrÃ©er un fichier CSV (`whisper_kriol_cm.csv`) avec les colonnes suivantes :

- `audio` â€” nom du fichier audio complet (ex : `Emilie_K.wav`)
- `start` / `end` â€” timestamps des segments (en secondes)
- `text` â€” transcription
- `variety` â€” Ã©tiquette de dialecte (ex : `CM`, `GB`)

### 2. Normaliser et vÃ©rifier

ExÃ©cuter les scripts suivants pour nettoyer les transcriptions :

```bash
python simple_normalization.py

```

### 3. Charger en dataset Hugging Face

Charger le fichier CSV dans un objet `datasets.DatasetDict` et le diviser en jeux d'entraÃ®nement et de test :

```python
from hf_dataset_loader import dataset  # prÃ©pare et divise en train/test

```

### 4. Tokeniser pour Whisper

Appliquer le `WhisperProcessor` pour gÃ©nÃ©rer les champs `input_features` et `labels` :

```python
from whisper_tokenizer import dataset  # ajoute input_features et labels
```
### 5. EntraÃ®ner

Soumettre l'entraÃ®nement sur SLURM :

```bash
sbatch whisper_train.slurm
```

Le modÃ¨le fine-tunÃ© sera sauvegardÃ© dans :

whisper-kriol-finetuned/

### 6. InfÃ©rence

Lancer une transcription sur un fichier `.wav` :

```bash
python whisper_infer.py
```
Les rÃ©sultats sont sauvegardÃ©s dans un fichier JSON

# Pipeline de Fine-Tuning avec Gervasio
Ã  rediger





